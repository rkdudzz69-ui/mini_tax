import io
import re
import pandas as pd
import streamlit as st

# (ì„ íƒ) OpenAI SDK
try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ì•ˆë‚´ë§Œ

# ==============================
# ê³µí†µ ì„¤ì •
# ==============================
st.set_page_config(page_title="ì‚¬ì—…ì íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°", layout="wide")
st.title("ì‚¬ì—…ì íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°")

# ==============================
# ì˜ˆì‹œ ë°ì´í„° (ì—…ë¡œë“œ ì—†ì„ ë•Œ ì‚¬ìš©)
# ==============================
SAMPLE_DATA = {
    "ìƒí˜¸": ["Aìƒì‚¬", "Bë¬´ì—­", "Cì‹ë‹¹", "Dì „ì", "Eìƒì ", "Fê¸°ì—…", "GìƒíšŒ"],
    "ì‚¬ì—…ìë²ˆí˜¸": ["111-11-11111", "222-22-22222", "333-33-33333", "444-44-44444", "555-55-55555", "666-66-66666", "777-77-77777"],
    "ëŒ€í‘œì": ["í™ê¸¸ë™", "ê¹€ì² ìˆ˜", "ì´ì˜í¬", "ë°•ë¯¼ìˆ˜", "ìµœìœ ì§„", "ì •ë‹¤í˜œ", "ì˜¤ì„±ë¯¼"],
    "ì£¼ë¯¼ë²ˆí˜¸": ["800101-1234567", "820202-2345678", "830303-3456789", "840404-4567890", "850505-5678901", "860606-6789012", "870707-7890123"],
    "ì‚¬ì—…ììƒíƒœ": ["ê³„ì†ì‚¬ì—…ì", "íì—…", "íì—…", "ê³„ì†ì‚¬ì—…ì", "íì—…", "ê³„ì†ì‚¬ì—…ì", "ê³„ì†ì‚¬ì—…ì"],
    "íì—…ì¼ì": ["", "2020-03-01", "2021-05-10", "", "2023-01-30", "", ""],
}

# ==============================
# ê³µí†µ ìœ í‹¸
# ==============================
@st.cache_data(show_spinner=False)
def load_df_from_file(file) -> pd.DataFrame:
    name = file.name.lower()
    if name.endswith(".csv"):
        content = file.read()
        for enc in ("utf-8-sig", "cp949", "euc-kr", "utf-8"):
            try:
                return pd.read_csv(io.BytesIO(content), encoding=enc)
            except Exception:
                continue
        return pd.read_csv(io.BytesIO(content), encoding_errors="ignore")
    else:
        return pd.read_excel(file)

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out.columns = [str(c).strip() for c in out.columns]
    for c in out.columns:
        if out[c].dtype == "object":
            out[c] = out[c].astype(str).str.strip()
    return out

def digits_only(s: str) -> str:
    return re.sub(r"[^0-9]", "", s or "")

def norm_text(s: str) -> str:
    return (s or "").strip().lower()

# ==============================
# ë°ì´í„° ë¡œë“œ
# ==============================
file = st.file_uploader("ì‚¬ì—…ë‚´ì—­ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, .xls, .csv)", type=["xlsx", "xls", "csv"])
if file:
    df = load_df_from_file(file)
else:
    st.info("ì—…ë¡œë“œê°€ ì—†ì–´ì„œ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì´ì•¼. ì‹¤ì œ íŒŒì¼ì„ ì˜¬ë¦¬ë©´ ê·¸ê±¸ë¡œ ë¶„ì„í•´!")
    df = pd.DataFrame(SAMPLE_DATA)

df = normalize_cols(df)

# í•„ìˆ˜ ì»¬ëŸ¼
required = {"ìƒí˜¸", "ì‚¬ì—…ìë²ˆí˜¸", "ëŒ€í‘œì", "ì£¼ë¯¼ë²ˆí˜¸", "ì‚¬ì—…ììƒíƒœ"}
missing = [c for c in required if c not in df.columns]
if missing:
    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ì–´ìš”: {', '.join(missing)}")
    st.stop()

# íì—…ì¼ì íŒŒì‹±
if "íì—…ì¼ì" in df.columns:
    df["íì—…ì¼ì"] = df["íì—…ì¼ì"].replace({"": pd.NA})
    df["íì—…ì¼ì(íŒŒì‹±)"] = pd.to_datetime(df["íì—…ì¼ì"], errors="coerce")
else:
    df["íì—…ì¼ì"] = pd.NA
    df["íì—…ì¼ì(íŒŒì‹±)"] = pd.NaT

# ==============================
# ì‚¬ì´ë“œë°” ì¹´í…Œê³ ë¦¬
# ==============================
st.sidebar.header("ì¹´í…Œê³ ë¦¬")
page = st.sidebar.radio(
    "ë³´ê¸° ì„ íƒ",
    ["ì‚¬ì—…ì ì¡°íšŒ", "ì „ì²´ íì—…ì ì¡°íšŒ", "ì—°ë„ë³„ íì—…ì ìˆ˜ í†µê³„", "ë™ì¼ ì‚¬ì—…ì(ëŒ€í‘œì/ì£¼ë¯¼ë²ˆí˜¸) ë‚´ì—­", "ğŸ¤– ì±—ë´‡"],
    index=0
)

# ==============================
# 1) ì‚¬ì—…ì ì¡°íšŒ (ë‹¤ì¤‘ ì…ë ¥ + ë„“ì€ ì…ë ¥ì¹¸ + ê°„ê²© ë„ìš´ ë²„íŠ¼)
# ==============================
def render_search(df: pd.DataFrame):
    st.markdown("## ğŸ” ì‚¬ì—…ì ì¡°íšŒ")
    st.caption("ì—¬ëŸ¬ ëª…/ì—¬ëŸ¬ ì¡°ê±´ì„ í•œ ë²ˆì— ê²€ìƒ‰í•  ìˆ˜ ìˆì–´ìš”. ê° ì…ë ¥ì¹¸ì€ ìƒí˜¸Â·ëŒ€í‘œìÂ·ì‚¬ì—…ìë²ˆí˜¸Â·ì£¼ë¯¼ë²ˆí˜¸ì— ë¶€ë¶„ ì¼ì¹˜ë¡œ ë§¤ì¹­ë©ë‹ˆë‹¤.")

    # ë§¤ì¹­ ë°©ì‹(í•œ ì¹¸ ì•ˆì˜ í‚¤ì›Œë“œ ê°„)
    match_mode = st.radio("ë§¤ì¹­ ë°©ì‹ (ê° ì…ë ¥ì¹¸ì— ì ìš©)", ["ë¶€ë¶„ í¬í•¨(AND)", "ë¶€ë¶„ í¬í•¨(OR)"], horizontal=True)

    # ì—¬ëŸ¬ ì…ë ¥ì¹¸(ì„¸ì…˜ ìƒíƒœ)
    if "multi_queries" not in st.session_state:
        st.session_state.multi_queries = [""]

    # ë²„íŠ¼(ì—¬ë°± ìˆëŠ” 3ì»¬ëŸ¼: ì¶”ê°€ / ë¹ˆì¹¸ / ì‚­ì œ)
    st.caption("ì…ë ¥ì¹¸ ì¶”ê°€ / ì‚­ì œ")
    col_add, col_gap, col_del, _ = st.columns([0.14, 0.06, 0.14, 4])
    with col_add:
        if st.button("ğŸŸ¥ï¼‹", key="add_query", use_container_width=True):
            st.session_state.multi_queries.append("")
    with col_del:
        if st.button("ğŸŸ¦ï¼", key="del_query", use_container_width=True) and len(st.session_state.multi_queries) > 1:
            st.session_state.multi_queries.pop()

    # ë„“ì€ ì…ë ¥ì¹¸
    new_vals = []
    for i, val in enumerate(st.session_state.multi_queries):
        with st.container():
            st.markdown(f"**ê²€ìƒ‰ì–´ #{i+1}**")
            new_vals.append(
                st.text_area(
                    label="",
                    value=val,
                    placeholder="ì˜ˆ) í™ê¸¸ë™ 111-11-11111 800101-1234567 (ê³µë°±ìœ¼ë¡œ ì—¬ëŸ¬ í‚¤ì›Œë“œ)",
                    height=56,
                    key=f"query_input_{i}",
                )
            )
    st.session_state.multi_queries = new_vals

    # ê²€ìƒ‰ ë¡œì§
    work = df.copy()
    work["_bnum_d"] = work["ì‚¬ì—…ìë²ˆí˜¸"].apply(digits_only)
    work["_rrn_d"] = work["ì£¼ë¯¼ë²ˆí˜¸"].apply(digits_only)

    def mask_for_one_query(q: str):
        q = (q or "").strip()
        if not q:
            return pd.Series([False]*len(work), index=work.index)
        terms = [t.strip() for t in q.split() if t.strip()]

        def row_match(row) -> bool:
            hay_text = " ".join([
                norm_text(row.get("ìƒí˜¸", "")),
                norm_text(row.get("ëŒ€í‘œì", "")),
                norm_text(row.get("ì‚¬ì—…ìë²ˆí˜¸", "")),
                norm_text(row.get("ì£¼ë¯¼ë²ˆí˜¸", "")),
            ])
            hay_digits = " ".join([row["_bnum_d"], row["_rrn_d"]])

            def contains(term: str) -> bool:
                t_txt = term.lower()
                t_dig = digits_only(term)
                ok_txt = (t_txt in hay_text) if t_txt else False
                ok_dig = (bool(t_dig) and t_dig in hay_digits)
                return ok_txt or ok_dig

            checks = [contains(t) for t in terms]
            return all(checks) if match_mode.startswith("ë¶€ë¶„ í¬í•¨(AND)") else any(checks)

        return work.apply(row_match, axis=1)

    masks = [mask_for_one_query(q) for q in st.session_state.multi_queries]
    if any(m.any() for m in masks):
        final_mask = pd.Series(False, index=work.index)
        for m in masks:
            final_mask |= m
        result = work.loc[final_mask].drop(columns=["_bnum_d", "_rrn_d"], errors="ignore")
    else:
        result = work.iloc[0:0]

    # ê²°ê³¼
    c1, c2 = st.columns(2)
    c1.metric("ì—…ë¡œë“œ í–‰ ìˆ˜", len(df))
    c2.metric("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", len(result))

    if all((q.strip() == "") for q in st.session_state.multi_queries):
        st.info("ê²€ìƒ‰ì–´ë¥¼ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì—¬ëŸ¬ ëª…ì„ ì°¾ìœ¼ë ¤ë©´ â€˜ğŸŸ¥ï¼‹â€™ ë²„íŠ¼ìœ¼ë¡œ ì…ë ¥ì¹¸ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    elif result.empty:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì² ì ë˜ëŠ” í•˜ì´í”ˆ(-) ìœ ë¬´ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")

    cols = ["ìƒí˜¸", "ì‚¬ì—…ìë²ˆí˜¸", "ëŒ€í‘œì", "ì£¼ë¯¼ë²ˆí˜¸", "ì‚¬ì—…ììƒíƒœ", "íì—…ì¼ì"]
    cols = [c for c in cols if c in result.columns]
    st.dataframe(result.reindex(columns=cols), use_container_width=True)

    if not result.empty:
        st.download_button(
            "â¬‡ï¸ ê²€ìƒ‰ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=result.reindex(columns=cols).to_csv(index=False).encode("utf-8-sig"),
            file_name="ì‚¬ì—…ì_ì¡°íšŒ_ê²°ê³¼.csv",
            mime="text/csv"
        )

# ==============================
# 2) ì „ì²´ íì—…ì ì¡°íšŒ
# ==============================
def render_closed_list(df: pd.DataFrame):
    st.markdown("## ğŸ“‹ ì „ì²´ íì—…ì ì¡°íšŒ")

    closed = df[df["ì‚¬ì—…ììƒíƒœ"].astype(str).str.strip() == "íì—…"].copy()

    enable_range = st.checkbox("íì—…ì¼ì ê¸°ê°„ìœ¼ë¡œ í•„í„°", value=False)
    if enable_range:
        min_d = pd.to_datetime(closed["íì—…ì¼ì(íŒŒì‹±)"]).min()
        max_d = pd.to_datetime(closed["íì—…ì¼ì(íŒŒì‹±)"]).max()
        c1, c2 = st.columns(2)
        start_date = c1.date_input("ì‹œì‘ì¼", value=min_d.date() if pd.notna(min_d) else None)
        end_date = c2.date_input("ì¢…ë£Œì¼", value=max_d.date() if pd.notna(max_d) else None)
        if start_date and end_date:
            m = (closed["íì—…ì¼ì(íŒŒì‹±)"] >= pd.to_datetime(start_date)) & (closed["íì—…ì¼ì(íŒŒì‹±)"] <= pd.to_datetime(end_date))
            closed = closed[m]

    c1, c2 = st.columns(2)
    c1.metric("íì—…ì ìˆ˜", len(closed))
    c2.metric("ì „ì²´ ëŒ€ë¹„ íì—… ë¹„ìœ¨", f"{(len(closed)/len(df)*100):.1f}%" if len(df) else "0.0%")

    cols = ["ìƒí˜¸", "ì‚¬ì—…ìë²ˆí˜¸", "ëŒ€í‘œì", "ì£¼ë¯¼ë²ˆí˜¸", "ì‚¬ì—…ììƒíƒœ", "íì—…ì¼ì"]
    cols = [c for c in cols if c in closed.columns]
    st.dataframe(closed.reindex(columns=cols), use_container_width=True)

    st.download_button(
        "â¬‡ï¸ íì—…ì ëª©ë¡ CSV ë‹¤ìš´ë¡œë“œ",
        data=closed.reindex(columns=cols).to_csv(index=False).encode("utf-8-sig"),
        file_name="ì „ì²´_íì—…ì_ëª©ë¡.csv",
        mime="text/csv"
    )

# ==============================
# 3) ì—°ë„ë³„ íì—…ì ìˆ˜ í†µê³„
# ==============================
def render_closed_by_year(df: pd.DataFrame):
    st.markdown("## ğŸ“ˆ ì—°ë„ë³„ íì—…ì ìˆ˜ í†µê³„")

    closed = df[df["ì‚¬ì—…ììƒíƒœ"].astype(str).str.strip() == "íì—…"].copy()
    closed["íì—…ì—°ë„"] = pd.to_datetime(closed["íì—…ì¼ì"], errors="coerce").dt.year

    years = sorted([int(y) for y in closed["íì—…ì—°ë„"].dropna().unique()]) if not closed.empty else []
    if years:
        y1, y2 = st.select_slider("ì—°ë„ ë²”ìœ„", options=years, value=(years[0], years[-1]))
        closed = closed[closed["íì—…ì—°ë„"].between(y1, y2)]
    else:
        st.info("íì—… ì—°ë„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    agg = (
        closed["íì—…ì—°ë„"]
        .dropna()
        .value_counts()
        .sort_index()
        .rename_axis("ì—°ë„")
        .reset_index(name="íì—…ì ìˆ˜")
    )

    st.dataframe(agg, use_container_width=True)
    if not agg.empty:
        st.bar_chart(agg.set_index("ì—°ë„"))

    st.download_button(
        "â¬‡ï¸ ì—°ë„ë³„ í†µê³„ CSV ë‹¤ìš´ë¡œë“œ",
        data=agg.to_csv(index=False).encode("utf-8-sig"),
        file_name="ì—°ë„ë³„_íì—…ì_í†µê³„.csv",
        mime="text/csv"
    )

# ==============================
# 4) ë™ì¼ ì‚¬ì—…ì ë‚´ì—­
# ==============================
def render_duplicates(df: pd.DataFrame):
    st.markdown("## ğŸ‘¥ ë™ì¼ ì‚¬ì—…ì(ëŒ€í‘œì/ì£¼ë¯¼ë²ˆí˜¸) ë‚´ì—­")

    dup_by_owner = df.groupby("ëŒ€í‘œì", dropna=False).size().reset_index(name="ê±´ìˆ˜")
    dup_by_owner = dup_by_owner[dup_by_owner["ê±´ìˆ˜"] > 1].sort_values("ê±´ìˆ˜", ascending=False)

    dup_by_rrn = df.groupby("ì£¼ë¯¼ë²ˆí˜¸", dropna=False).size().reset_index(name="ê±´ìˆ˜")
    dup_by_rrn = dup_by_rrn[dup_by_rrn["ê±´ìˆ˜"] > 1].sort_values("ê±´ìˆ˜", ascending=False)

    st.subheader("ì¤‘ë³µ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ëŒ€í‘œì ê¸°ì¤€ ì¤‘ë³µ**")
        st.dataframe(dup_by_owner, use_container_width=True, height=260)
    with c2:
        st.markdown("**ì£¼ë¯¼ë²ˆí˜¸ ê¸°ì¤€ ì¤‘ë³µ**")
        st.dataframe(dup_by_rrn, use_container_width=True, height=260)

    st.download_button(
        "â¬‡ï¸ ëŒ€í‘œì ì¤‘ë³µ ìš”ì•½ CSV",
        data=dup_by_owner.to_csv(index=False).encode("utf-8-sig"),
        file_name="ëŒ€í‘œì_ì¤‘ë³µ_ìš”ì•½.csv",
        mime="text/csv"
    )
    st.download_button(
        "â¬‡ï¸ ì£¼ë¯¼ë²ˆí˜¸ ì¤‘ë³µ ìš”ì•½ CSV",
        data=dup_by_rrn.to_csv(index=False).encode("utf-8-sig"),
        file_name="ì£¼ë¯¼ë²ˆí˜¸_ì¤‘ë³µ_ìš”ì•½.csv",
        mime="text/csv"
    )

# ==============================
# 5) ğŸ¤– ì±—ë´‡ (OpenAI)
# ==============================
def render_chatbot():
    st.markdown("## ğŸ¤– ì±—ë´‡")
    st.caption("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ê³  ì•„ë˜ì—ì„œ ì§ˆë¬¸í•´ ë´. (í‚¤ëŠ” ì„¸ì…˜ì—ë§Œ ì €ì¥)")

    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    if "openai_api_key" not in st.session_state:
        st.session_state.openai_api_key = ""

    key = st.text_input("OpenAI API Key", type="password", placeholder="sk-...", value=st.session_state.openai_api_key)
    if key != st.session_state.openai_api_key:
        st.session_state.openai_api_key = key

    model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"], index=0)
    st.divider()

    for msg in st.session_state.chat_messages:
        with st.chat_message("user" if msg["role"] == "user" else "assistant"):
            st.markdown(msg["content"])

    prompt = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´! (ì˜ˆ: íŠ¹ì • ëŒ€í‘œìì˜ íì—… ì—°ë„ë§Œ ì¶”ë ¤ì¤˜)")
    if prompt:
        if not st.session_state.openai_api_key:
            st.warning("ë¨¼ì € OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ ì¤˜.")
            return
        if OpenAI is None:
            st.error("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„. requirements.txtì— openai>=1.0.0 ì¶”ê°€í•´ ì¤˜.")
            return

        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            client = OpenAI(api_key=st.session_state.openai_api_key)
            sys_prompt = (
                "ë„ˆëŠ” ì„¸ë¬´/ì‚¬ì—…ì ë°ì´í„° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. "
                "ì§ˆë¬¸ì„ ëª…í™•íˆ ì´í•´í•˜ê³ , í•„ìš”í•˜ë©´ í‘œë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•´ ë‹µí•´ì¤˜."
            )
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": sys_prompt}, *st.session_state.chat_messages],
                temperature=0.3,
            )
            answer = resp.choices[0].message.content.strip()
        except Exception as e:
            answer = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´: {e}"

        st.session_state.chat_messages.append({"role": "assistant", "content": answer})
        with st.chat_message("assistant"):
            st.markdown(answer)

        chat_df = pd.DataFrame(st.session_state.chat_messages)
        st.download_button(
            "â¬‡ï¸ ëŒ€í™” ë‚´ë³´ë‚´ê¸° (CSV)",
            data=chat_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="chat_history.csv",
            mime="text/csv"
        )

# ==============================
# ë¼ìš°íŒ…
# ==============================
if page == "ì‚¬ì—…ì ì¡°íšŒ":
    render_search(df)
elif page == "ì „ì²´ íì—…ì ì¡°íšŒ":
    render_closed_list(df)
elif page == "ì—°ë„ë³„ íì—…ì ìˆ˜ í†µê³„":
    render_closed_by_year(df)
elif page == "ë™ì¼ ì‚¬ì—…ì(ëŒ€í‘œì/ì£¼ë¯¼ë²ˆí˜¸) ë‚´ì—­":
    render_duplicates(df)
else:
    render_chatbot()
